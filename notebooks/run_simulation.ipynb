{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import traceback\n",
    "import logging\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from typing import List, Optional\n",
    "from torch import multiprocessing as mp\n",
    "from multiprocessing.pool import Pool\n",
    "from multiprocessing import Queue, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dqnroute import event_series, run_network_scenario, run_conveyor_scenario,\\\n",
    "                     DQNROUTE_LOGGER, TF_MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(DQNROUTE_LOGGER)\n",
    "TORCH_MODELS_DIR = '../torch_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_job_id(router_type, seed):\n",
    "    return '{}:{}'.format(router_type, seed)\n",
    "\n",
    "def un_job_id(job_id):\n",
    "    [router_type, s_seed] = job_id.split(':')\n",
    "    return router_type, int(s_seed)\n",
    "\n",
    "def add_avg(df: pd.DataFrame):\n",
    "    df['avg'] = df['sum'] / df['count']\n",
    "    return df\n",
    "\n",
    "def plot_data(figsize=(15,5), xlim=None, ylim=None, target='avg', **dfs):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    handles = []\n",
    "    min_target = 'min_' + target\n",
    "    max_target = 'max_' + target\n",
    "    \n",
    "    for (label, df) in dfs.items():\n",
    "        if min_target in df.columns:\n",
    "            # this is combined data, draw errorbar\n",
    "            minerr = df[target] - df[min_target]\n",
    "            maxerr = df[max_target] - df[target]\n",
    "            line = plt.errorbar(df['time'], df[target],\n",
    "                                yerr=[minerr, maxerr], label=label)\n",
    "        else:\n",
    "            line, = plt.plot(df['time'], df[target], label=label)\n",
    "        handles.append(line)\n",
    "        \n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "        \n",
    "    plt.legend(handles=handles)\n",
    "    plt.show()\n",
    "\n",
    "def split_data(dct):\n",
    "    results = []\n",
    "    \n",
    "    def add_res(i, key, val):\n",
    "        while len(results) <= i:\n",
    "            results.append({})\n",
    "        results[i][key] = val\n",
    "    \n",
    "    for (key, vals) in dct.items():\n",
    "        for (i, val) in enumerate(vals):\n",
    "            add_res(i, key, val)\n",
    "    return tuple(results)\n",
    "    \n",
    "def combine_launch_data(launch_data, target='avg'):\n",
    "    data_unwrapped = {}\n",
    "    for (job_id, data) in launch_data.items():\n",
    "        router_type, seed = un_job_id(job_id)\n",
    "        if router_type not in data_unwrapped:\n",
    "            data_unwrapped[router_type] = []\n",
    "        data_unwrapped[router_type].append(data)\n",
    "    \n",
    "    result_data = {}\n",
    "    min_target = 'min_' + target\n",
    "    max_target = 'max_' + target\n",
    "    for (router_type, runs) in data_unwrapped.items():\n",
    "        df = runs[0].copy()\n",
    "        df[min_target] = df[target]\n",
    "        df[max_target] = df[target]\n",
    "        for run in runs[1:]:\n",
    "            df['sum'] += run['sum']\n",
    "            df['count'] += run['count']\n",
    "            df[min_target] = df[min_target].combine(run[target], min)\n",
    "            df[max_target] = df[max_target].combine(run[target], max)\n",
    "            \n",
    "        # averaging all meaningfull data across runs\n",
    "        df = add_avg(df)\n",
    "        df['sum'] /= len(runs) \n",
    "        df['count'] /= len(runs)\n",
    "        \n",
    "        result_data[router_type] = df\n",
    "        \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTqdmFile(object):\n",
    "    \"\"\"Dummy file-like that will write to tqdm\"\"\"\n",
    "    file = None\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def write(self, x):\n",
    "        # Avoid print() second call (useless \\n)\n",
    "        if len(x.rstrip()) > 0:\n",
    "            tqdm.write(x, file=self.file)\n",
    "\n",
    "    def flush(self):\n",
    "        return getattr(self.file, \"flush\", lambda: None)()\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def std_out_err_redirect_tqdm():\n",
    "    orig_out_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = map(DummyTqdmFile, orig_out_err)\n",
    "        yield orig_out_err[0]\n",
    "    # Relay exceptions\n",
    "    except Exception as exc:\n",
    "        raise exc\n",
    "    # Always restore sys.stdout/err if necessary\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = orig_out_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyProgressbarQueue:\n",
    "    def __init__(self, bar):\n",
    "        self.bar = bar\n",
    "        \n",
    "    def put(self, val):\n",
    "        _, _, delta = val\n",
    "        if delta is not None:\n",
    "            self.bar.update(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network_scenario_file(file: str, router_type: str, random_seed: int = None,\n",
    "                              progress_step: Optional[int] = None, progress_queue: Optional[Queue] = None,\n",
    "                              series_period: int = 500,\n",
    "                              series_funcs: List[str] = ['count', 'sum', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Helper wrapper around `run_network_scenario` which should run in a separate thread.\n",
    "    \"\"\"    \n",
    "    with open(file) as f:\n",
    "        run_params = yaml.safe_load(f)\n",
    "    \n",
    "    series = event_series(series_period, series_funcs)\n",
    "    series = run_network_scenario(run_params, router_type, series, random_seed=random_seed,\n",
    "                                  progress_step=progress_step, progress_queue=progress_queue)\n",
    "    return add_avg(series.getSeries())\n",
    "\n",
    "def run_conveyor_scenario_file(file: str, router_type: str, random_seed: int = None,\n",
    "                               progress_step: Optional[int] = None, progress_queue: Optional[Queue] = None,\n",
    "                               series_period: int = 500,\n",
    "                               series_funcs: List[str] = ['count', 'sum', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Helper wrapper around `run_conveyor_scenario` which should run in a separate thread.\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        run_params = yaml.safe_load(f)\n",
    "    \n",
    "    time_series = event_series(series_period, series_funcs)\n",
    "    energy_series = event_series(series_period, series_funcs)\n",
    "    \n",
    "    time_series, energy_series = \\\n",
    "        run_conveyor_scenario(run_params, router_type, time_series, energy_series,\n",
    "                              random_seed=random_seed,\n",
    "                              progress_step=progress_step, progress_queue=progress_queue)\n",
    "    \n",
    "    return add_avg(time_series.getSeries()), add_avg(energy_series.getSeries())\n",
    "\n",
    "def exc_print(e):\n",
    "    print(''.join(traceback.format_exception(etype=type(e), value=e, tb=e.__traceback__)))\n",
    "\n",
    "def run_threaded(func, router_types: List[str], random_seeds: List[int], *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Runs several scenario runners in multiple threads and displays progress bars for them\n",
    "    \"\"\"\n",
    "\n",
    "    pool = Pool()\n",
    "    m = Manager()\n",
    "    queue = m.Queue()\n",
    "    jobs = {}\n",
    "    bars = {}\n",
    "    for router_type in router_types:\n",
    "        for seed in random_seeds:\n",
    "            job_id = mk_job_id(router_type, seed)\n",
    "            job_args = dict(kwargs, router_type=router_type, random_seed=seed,\n",
    "                            progress_queue=queue)\n",
    "            jobs[job_id] = pool.apply_async(func, args=args, kwds=job_args,\n",
    "                                            error_callback=exc_print)\n",
    "            bars[job_id] = tqdm_notebook(desc=job_id)\n",
    "\n",
    "    # TODO: fix progressbars somehow\n",
    "    while len(bars) > 0:\n",
    "        (rt, s, val) = queue.get()\n",
    "        job_id = mk_job_id(rt, s)\n",
    "        if val is None:\n",
    "            bars.pop(job_id).close()\n",
    "        else:\n",
    "            bars[job_id].update(val)\n",
    "        \n",
    "    results = {job_id: job.get() for (job_id, job) in jobs.items()}\n",
    "    \n",
    "    if type(next(iter(results.values()))) is tuple:\n",
    "        return split_data(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch6_data_mult = run_threaded(run_network_scenario_file, random_seeds=[42, 43, 44],\n",
    "                                 file='../launches/launch6.yaml', router_types=['simple_q', 'link_state', 'dqn'],\n",
    "                                 progress_step=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch6_data_comb = combine_launch_data(launch6_data_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(figsize=(10,6), ylim=(0,450), **launch6_data_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch8_data = run_threaded(run_network_scenario_file, file='../launches/launch8.yaml',\n",
    "                            router_types=['simple_q', 'link_state', 'dqn'], progress_step=500,\n",
    "                            random_seeds=[42, 43, 44])\n",
    "\n",
    "launch8_data_comb = combine_launch_data(launch8_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(figsize=(13,10), **launch8_data_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_data_full = run_threaded(run_conveyor_scenario_file, file='../launches/conveyor_energy_test.yaml',\n",
    "                                  router_types=['simple_q', 'link_state', 'dqn'], progress_step=500,\n",
    "                                  random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_data_time, conveyor_data_nrg = conveyor_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_data_time_comb = combine_launch_data(conveyor_data_time)\n",
    "conveyor_data_nrg_comb = combine_launch_data(conveyor_data_nrg, target='sum')\n",
    "\n",
    "plot_data(**conveyor_data_time_comb)\n",
    "plot_data(**conveyor_data_nrg_comb, target='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor2_data_full = run_threaded(run_conveyor_scenario_file, file='../launches/conveyor_energy_test_2.yaml',\n",
    "                                   router_types=['link_state', 'simple_q', 'dqn'], progress_step=500,\n",
    "                                   random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor2_data_time, conveyor2_data_nrg = conveyor2_data_full\n",
    "conveyor2_data_time_comb = combine_launch_data(conveyor2_data_time)\n",
    "conveyor2_data_nrg_comb = combine_launch_data(conveyor2_data_nrg, target='sum')\n",
    "\n",
    "plot_data(**conveyor2_data_time_comb)\n",
    "plot_data(**conveyor2_data_nrg_comb, target='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
