{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import traceback\n",
    "import logging\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from typing import List, Optional, Union\n",
    "from torch import multiprocessing as mp\n",
    "from multiprocessing.pool import Pool\n",
    "from multiprocessing import Queue, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dqnroute import event_series, NetworkRunner, ConveyorsRunner,\\\n",
    "                     MultiEventSeries, DQNROUTE_LOGGER, TF_MODELS_DIR, LOG_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(DQNROUTE_LOGGER)\n",
    "TORCH_MODELS_DIR = '../torch_models'\n",
    "LOG_DATA_DIR = '../logs/runs'\n",
    "\n",
    "np.set_printoptions(linewidth=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_legend_txt_replace = {\n",
    "    'link_state': 'Shortest paths',\n",
    "    'simple_q': 'Q-routing',\n",
    "    'pred_q': 'PQ-routing',\n",
    "    'glob_dyn': 'Global-dynamic',\n",
    "    'dqn': 'DQN',\n",
    "    'dqn_oneout': 'DQN (1-out)',\n",
    "    'dqn_emb': 'DQN-LE',\n",
    "}\n",
    "\n",
    "def mk_job_id(router_type, seed):\n",
    "    return '{}-{}'.format(router_type, seed)\n",
    "\n",
    "def un_job_id(job_id):\n",
    "    [router_type, s_seed] = job_id.split('-')\n",
    "    return router_type, int(s_seed)\n",
    "\n",
    "def add_avg(df: pd.DataFrame):\n",
    "    df['avg'] = df['sum'] / df['count']\n",
    "    return df\n",
    "\n",
    "def plot_data(data, figsize=(15,5), xlim=None, ylim=None, target='avg',\n",
    "              xlabel='Время симулятора', ylabel='Среднее время пакета в пути',\n",
    "              font_size=14, title=None, save_path=None):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = sns.lineplot(x='time', y=target, hue='router_type', data=data,\n",
    "                      err_kws={'alpha': 0.1})\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_labels = list(map(lambda l: _legend_txt_replace.get(l, l), labels[1:]))\n",
    "    ax.legend(handles=handles[1:], labels=new_labels, fontsize=font_size)\n",
    "        \n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax.set_xlabel(xlabel, fontsize=font_size)\n",
    "    ax.set_ylabel(ylabel, fontsize=font_size)\n",
    "    \n",
    "    plt.show(fig)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        fig.savefig('../img/' + save_path, bbox_inches='tight')\n",
    "\n",
    "def split_data(dct):\n",
    "    results = []\n",
    "    \n",
    "    def add_res(i, key, val):\n",
    "        while len(results) <= i:\n",
    "            results.append({})\n",
    "        results[i][key] = val\n",
    "    \n",
    "    for (key, vals) in dct.items():\n",
    "        for (i, val) in enumerate(vals):\n",
    "            add_res(i, key, val)\n",
    "    return tuple(results)\n",
    "    \n",
    "def add_cols(df, **cols):\n",
    "    for (col, val) in cols.items():\n",
    "        df.loc[:, col] = val\n",
    "    \n",
    "def combine_launch_data(launch_data):\n",
    "    dfs = []\n",
    "    for (job_id, data) in launch_data.items():\n",
    "        router_type, seed = un_job_id(job_id)\n",
    "        df = data.copy()\n",
    "        add_cols(df, router_type=router_type, seed=seed)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTqdmFile(object):\n",
    "    \"\"\"Dummy file-like that will write to tqdm\"\"\"\n",
    "    file = None\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def write(self, x):\n",
    "        # Avoid print() second call (useless \\n)\n",
    "        if len(x.rstrip()) > 0:\n",
    "            tqdm.write(x, file=self.file)\n",
    "\n",
    "    def flush(self):\n",
    "        return getattr(self.file, \"flush\", lambda: None)()\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def std_out_err_redirect_tqdm():\n",
    "    orig_out_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = map(DummyTqdmFile, orig_out_err)\n",
    "        yield orig_out_err[0]\n",
    "    # Relay exceptions\n",
    "    except Exception as exc:\n",
    "        raise exc\n",
    "    # Always restore sys.stdout/err if necessary\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = orig_out_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyProgressbarQueue:\n",
    "    def __init__(self, bar):\n",
    "        self.bar = bar\n",
    "        \n",
    "    def put(self, val):\n",
    "        _, delta = val\n",
    "        if delta is not None:\n",
    "            self.bar.update(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network_scenario_file(file: str, router_type: str, random_seed: int = None,\n",
    "                              progress_step: Optional[int] = None, progress_queue: Optional[Queue] = None,\n",
    "                              ignore_saved=False, series_period: int = 500,\n",
    "                              series_funcs: List[str] = ['count', 'sum', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Helper wrapper around `NetworkEnvironment` which should run in a separate thread.\n",
    "    \"\"\"    \n",
    "    with open(file) as f:\n",
    "        run_params = yaml.safe_load(f)\n",
    "    \n",
    "    series = event_series(series_period, series_funcs)\n",
    "    runner = NetworkRunner(run_params=run_params, router_type=router_type, data_series=series)\n",
    "    \n",
    "    series = runner.run(random_seed=random_seed, ignore_saved=ignore_saved,\n",
    "                        progress_step=progress_step, progress_queue=progress_queue)\n",
    "    \n",
    "    return add_avg(series.getSeries())\n",
    "\n",
    "def run_conveyor_scenario_file(file: str, router_type: str, random_seed: int = None,\n",
    "                               progress_step: Optional[int] = None, progress_queue: Optional[Queue] = None,\n",
    "                               ignore_saved=False, series_period: int = 500,\n",
    "                               series_funcs: List[str] = ['count', 'sum', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Helper wrapper around `ConveyorsEnvironment` which should run in a separate thread.\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        run_params = yaml.safe_load(f)\n",
    "    \n",
    "    time_series = event_series(series_period, series_funcs)\n",
    "    energy_series = event_series(series_period, series_funcs)\n",
    "    series = MultiEventSeries(time=time_series, energy=energy_series)\n",
    "    \n",
    "    runner = ConveyorsRunner(run_params=run_params, router_type=router_type, data_series=series)\n",
    "    series = runner.run(random_seed=random_seed, ignore_saved=ignore_saved,\n",
    "                        progress_step=progress_step, progress_queue=progress_queue)\n",
    "    \n",
    "    return add_avg(time_series.getSeries()), add_avg(energy_series.getSeries())\n",
    "\n",
    "def run_single(func, router_type: str, random_seed: int, **kwargs):\n",
    "    job_id = mk_job_id(router_type, random_seed)\n",
    "    with tqdm_notebook(desc=job_id) as bar:\n",
    "        queue = DummyProgressbarQueue(bar)\n",
    "        results = func(router_type=router_type, random_seed=random_seed,\n",
    "                       progress_queue=queue, **kwargs) \n",
    "     \n",
    "    if type(results) is tuple:\n",
    "        for df in results:\n",
    "            add_cols(df, router_type=router_type, seed=random_seed)\n",
    "    else:\n",
    "        add_cols(results, router_type=router_type, seed=random_seed)\n",
    "    return results\n",
    "\n",
    "def exc_print(e):\n",
    "    print(''.join(traceback.format_exception(etype=type(e), value=e, tb=e.__traceback__)))\n",
    "\n",
    "def run_threaded(func, router_types: List[str], random_seeds: List[int],\n",
    "                 ignore_saved: Union[bool, List[str]] = [], *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Runs several scenario runners in multiple threads and displays progress bars for them\n",
    "    \"\"\"\n",
    "\n",
    "    pool = Pool()\n",
    "    m = Manager()\n",
    "    queue = m.Queue()\n",
    "    jobs = {}\n",
    "    bars = {}\n",
    "    if ignore_saved == True:\n",
    "        ignore_saved = router_types\n",
    "    \n",
    "    for router_type in router_types:\n",
    "        for seed in random_seeds:\n",
    "            job_id = mk_job_id(router_type, seed)\n",
    "            job_args = dict(kwargs, router_type=router_type, random_seed=seed,\n",
    "                            ignore_saved=router_type in ignore_saved, progress_queue=queue)\n",
    "            jobs[job_id] = pool.apply_async(func, args=args, kwds=job_args,\n",
    "                                            error_callback=exc_print)\n",
    "            bars[job_id] = tqdm_notebook(desc=job_id)\n",
    "\n",
    "    while len(bars) > 0:\n",
    "        (job_id, val) = queue.get()\n",
    "        if val is None:\n",
    "            bars.pop(job_id).close()\n",
    "        else:\n",
    "            bars[job_id].update(val)\n",
    "        \n",
    "    results = {job_id: job.get() for (job_id, job) in jobs.items()}\n",
    "    \n",
    "    if type(next(iter(results.values()))) is tuple:\n",
    "        return split_data(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_pretrain = pd.read_csv('../logs/results5_no_pretrain_dqn.csv', index_col=0)\n",
    "results5_ls = pd.read_csv('../logs/results5_link_state.csv', index_col=0)\n",
    "res5_comb = combine_launch_data({'link_state-42': results5_ls, 'dqn-42': results_no_pretrain})\n",
    "plot_data(res5_comb, ylim=(0, 700), xlim=(0, 40000), ylabel='Среднее время в пути')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch6_data_mult = run_threaded(run_network_scenario_file, random_seeds=[42, 43, 44],\n",
    "                                 file='../launches/launch6.yaml', router_types=['link_state', 'simple_q', 'dqn', 'dqn_emb'],\n",
    "                                 ignore_saved=['link_state'], progress_step=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch6_data_comb = combine_launch_data(launch6_data_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(launch6_data_comb, figsize=(10,6), ylim=(0, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch8_data = run_threaded(run_network_scenario_file, file='../launches/launch8.yaml',\n",
    "                            router_types=['link_state', 'simple_q', 'dqn', 'dqn_emb'], progress_step=500,\n",
    "                            ignore_saved=['link_state', 'simple_q'], random_seeds=[42, 43, 44])\n",
    "\n",
    "launch8_data_comb = combine_launch_data(launch8_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(launch8_data_comb, figsize=(15, 10), ylim=(35, 140), xlim=(-300, 35000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_calm_data = run_threaded(run_network_scenario_file, file='../launches/launch_long_calm.yaml',\n",
    "                                router_types=['link_state', 'dqn', 'dqn_emb'], progress_step=500,\n",
    "                                ignore_saved=[], random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(combine_launch_data(launch_calm_data), xlim=(0, 40000), ylim=(0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_rand_data = run_threaded(run_network_scenario_file, file='../launches/launch_dqn_transfer.yaml',\n",
    "                                router_types=['link_state', 'dqn', 'dqn_emb'], progress_step=500,\n",
    "                                ignore_saved=[], random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(combine_launch_data(launch_rand_data), figsize=(10, 6),\n",
    "          ylim=(20, 150), xlim=(-500, 20000), save_path='learning-transfer-small.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_rand_data_big = run_threaded(run_network_scenario_file, file='../launches/launch_rand_big.yaml',\n",
    "                                    router_types=['link_state', 'simple_q', 'dqn_emb'], progress_step=500,\n",
    "                                    ignore_saved=[], random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_rand_data_comb = combine_launch_data(launch_rand_data_big)\n",
    "plot_data(launch_rand_data_comb, figsize=(6, 6), ylim=(30, 300), xlim=(-500, 50000),\n",
    "          save_path='learning-transfer-big-low-load.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_data = run_single(run_conveyor_scenario_file, file='../launches/conveyor_energy_test.yaml',\n",
    "                        router_type='simple_q', ignore_saved=True, random_seed=42, progress_step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data, eng_data = debug_data\n",
    "plot_data(time_data)\n",
    "plot_data(eng_data, target='sum', ylabel='Энергия')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_data_full = run_threaded(run_conveyor_scenario_file, file='../launches/conveyor_energy_test.yaml',\n",
    "                                  router_types=['link_state', 'simple_q', 'dqn_emb'], progress_step=500,\n",
    "                                  ignore_saved=[], random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_data_time, conveyor_data_nrg = conveyor_data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_data_time_comb = combine_launch_data(conveyor_data_time)\n",
    "conveyor_data_nrg_comb = combine_launch_data(conveyor_data_nrg)\n",
    "\n",
    "plot_data(conveyor_data_time_comb, figsize=(15, 10), font_size=18)\n",
    "plot_data(conveyor_data_nrg_comb, figsize=(15, 10), font_size=18,\n",
    "          target='sum', ylabel='Суммарные энергозатраты')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor2_data_full = run_threaded(run_conveyor_scenario_file, file='../launches/conveyor_energy_test_2.yaml',\n",
    "                                   router_types=['link_state', 'simple_q', 'dqn', 'dqn_emb'], progress_step=500,\n",
    "                                   ignore_saved=[], random_seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor2_data_time, conveyor2_data_nrg = conveyor2_data_full\n",
    "conveyor2_data_time_comb = combine_launch_data(conveyor2_data_time)\n",
    "conveyor2_data_nrg_comb = combine_launch_data(conveyor2_data_nrg)\n",
    "\n",
    "plot_data(conveyor2_data_time_comb, figsize=(10, 10), ylim=(40, 100), font_size=18,\n",
    "          save_path='conveyors2-late-time.pdf')\n",
    "plot_data(conveyor2_data_nrg_comb, figsize=(10, 10), font_size=18, ylim=(1000, 2700),\n",
    "          target='sum', ylabel='Суммарные энергозатраты', save_path='conveyors2-late-energy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
