{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import hashlib\n",
    "import base64\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dqnroute.utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = get_target_cols(10)\n",
    "neighbors_cols = get_neighbors_cols(10)\n",
    "addr_cols = get_addr_cols(10)\n",
    "dst_cols = get_dst_cols(10)\n",
    "amatrix_cols = get_amatrix_cols(10)\n",
    "left_cols = ['time', 'pkg_id']+neighbors_cols+amatrix_cols+target_cols\n",
    "new_cols = ['dst', 'addr'] + left_cols\n",
    "new_cols_2 = ['time', 'pkg_id', 'dst', 'addr', 'neighbour'] + amatrix_cols + ['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../logs/data_generated2_new.csv', names=new_cols)\n",
    "data = pd.read_csv('../logs/data_generated2_new_one_inp.csv', index_col=0)\n",
    "data = data.reindex(np.arange(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dqnroute.networks import *\n",
    "from dqnroute.utils import stack_batch\n",
    "from functools import partial\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(df):\n",
    "    return df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "def find_first_sublist(seq, sublist, start=0):\n",
    "    length = len(sublist)\n",
    "    for index in range(start, len(seq)):\n",
    "        if seq[index:index+length] == sublist:\n",
    "            return index, index+length\n",
    "\n",
    "def replace_sublist(seq, sublist, replacement):\n",
    "    length = len(replacement)\n",
    "    index = 0\n",
    "    for start, end in iter(lambda: find_first_sublist(seq, sublist, index), None):\n",
    "        seq[start:end] = replacement\n",
    "        index = start + length\n",
    "    return seq\n",
    "\n",
    "def transform_to_one_out(df):\n",
    "    old_cols = list(df.columns)\n",
    "    neighbors_cols = [col for col in old_cols if col.startswith('neighbors')]\n",
    "    target_cols = [col for col in old_cols if col.startswith('predict')]\n",
    "    \n",
    "    new_cols = replace_sublist(replace_sublist(old_cols, neighbors_cols, ['neighbour']),\n",
    "                               target_cols, ['predict'])\n",
    "    row_ix = 0\n",
    "    nums = pd.Series(range(len(neighbors_cols)), index=neighbors_cols)\n",
    "    new_rows_num = df[neighbors_cols].sum().sum()\n",
    "    df_new = pd.DataFrame(columns=new_cols, index=np.arange(new_rows_num), dtype=np.float32)\n",
    "    \n",
    "    for idx, row in tqdm_notebook(df.iterrows(), total=len(df)):\n",
    "        nbrs = nums[row[neighbors_cols] != 0]\n",
    "        preds = list(row[target_cols][row != -1000000])        \n",
    "        new_row_tpl = row.drop(neighbors_cols + target_cols)\n",
    "        \n",
    "        for (nbr, pred) in zip(nbrs, preds):\n",
    "            new_row = new_row_tpl\n",
    "            new_row['neighbour'] = nbr\n",
    "            new_row['predict'] = pred\n",
    "            df_new.loc[row_ix] = new_row\n",
    "            row_ix += 1\n",
    "        \n",
    "    return df_new.reindex(np.arange(len(df_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_graph(graph):\n",
    "    if type(graph) != np.ndarray:\n",
    "        graph = nx.to_numpy_matrix(graph, nodelist=sorted(graph.nodes))\n",
    "    m = hashlib.sha256()\n",
    "    m.update(graph.tobytes())\n",
    "    return base64.b64encode(m.digest()).decode('utf-8')\n",
    "\n",
    "class CachedEmbedding(Embedding):\n",
    "    def __init__(self, InnerEmbedding, dim, **kwargs):\n",
    "        self.dim = dim\n",
    "        self.InnerEmbedding = InnerEmbedding\n",
    "        self.inner_kwargs = kwargs\n",
    "        self.fit_embeddings = {}\n",
    "        \n",
    "    def fit(self, graph, **kwargs):\n",
    "        h = hash_graph(graph)\n",
    "        if h not in self.fit_embeddings:\n",
    "            embed = self.InnerEmbedding(dim=self.dim, **self.inner_kwargs)\n",
    "            embed.fit(graph, **kwargs)\n",
    "            self.fit_embeddings[h] = embed\n",
    "    \n",
    "    def transform(self, graph, idx):\n",
    "        h = hash_graph(graph)\n",
    "        return self.fit_embeddings[h].transform(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_or_emb(vals, embedding=None):\n",
    "    if embedding is None:\n",
    "        return vals\n",
    "    return embedding.get_embedding(vals.astype(int))\n",
    "\n",
    "def qnetwork_batches(net, data, batch_size=64, embedding=None):\n",
    "    n = net.graph_size\n",
    "    data_cols = []\n",
    "    amatrix_cols = get_amatrix_cols(n)\n",
    "    \n",
    "    for (tag, dim) in net.add_inputs:\n",
    "        if tag == 'amatrix':\n",
    "            data_cols.append(amatrix_cols)\n",
    "        else:\n",
    "            data_cols.append(mk_num_list(tag + '_', n))\n",
    "\n",
    "    for (a, b) in make_batches(data.shape[0], batch_size):\n",
    "        batch = data[a:b]\n",
    "        addr = batch['addr'].values\n",
    "        dst = batch['dst'].values\n",
    "        nbr = batch['neighbour'].values\n",
    "        \n",
    "        if embedding is not None:\n",
    "            amatrices = batch[amatrix_cols].values\n",
    "            new_btch = []\n",
    "            for (addr_, dst_, nbr_, A) in zip(addr, dst, nbr, amatrices):\n",
    "                A = 10 * A.reshape(n, n)\n",
    "                embedding.fit(A)\n",
    "                new_addr = embedding.transform(A, int(addr_))\n",
    "                new_dst = embedding.transform(A, int(dst_))\n",
    "                new_nbr = embedding.transform(A, int(nbr_))\n",
    "                new_btch.append((new_addr, new_dst, new_nbr))\n",
    "                \n",
    "            [addr, dst, nbr] = stack_batch(new_btch)\n",
    "            \n",
    "        addr_inp = torch.tensor(addr, dtype=torch.float)\n",
    "        dst_inp = torch.tensor(dst, dtype=torch.float)\n",
    "        nbr_inp = torch.tensor(nbr, dtype=torch.float)\n",
    "                \n",
    "        inputs = tuple(torch.tensor(batch[cols].values, dtype=torch.float)\n",
    "                       for cols in data_cols)\n",
    "        output = torch.tensor(batch['predict'].values, dtype=torch.float)\n",
    "        \n",
    "        yield ((addr_inp, dst_inp, nbr_inp) + inputs, output)\n",
    "\n",
    "def qnetwork_pretrain_epoch(net, optimizer, data, **kwargs):\n",
    "    loss_func = nn.MSELoss()\n",
    "    for (batch, target) in qnetwork_batches(net, data, **kwargs):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(*batch)\n",
    "        loss = loss_func(output, target.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        yield float(loss)\n",
    "        \n",
    "def qnetwork_pretrain(net, data, optimizer='rmsprop', epochs=1,\n",
    "                      save_net=True, **kwargs):\n",
    "    optimizer = get_optimizer(optimizer)(net.parameters())\n",
    "    epochs_losses = []\n",
    "    \n",
    "    for i in tqdm_notebook(range(epochs)):\n",
    "        sum_loss = 0\n",
    "        loss_cnt = 0\n",
    "        for loss in tqdm_notebook(qnetwork_pretrain_epoch(net, optimizer, data, **kwargs),\n",
    "                                  desc='epoch {}'.format(i)):\n",
    "            sum_loss += loss\n",
    "            loss_cnt += 1\n",
    "        epochs_losses.append(sum_loss / loss_cnt)\n",
    "        \n",
    "    if save_net:\n",
    "        net.save()\n",
    "    \n",
    "    return epochs_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses_dict, from_epoch=0, num_epochs=None,\n",
    "                fsize=16, figsize=(13, 7), title=None):\n",
    "    if num_epochs is None:\n",
    "        num_epochs = len(next(iter(losses_dict.values())))\n",
    "        \n",
    "    x = range(from_epoch+1, num_epochs+1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for (label, losses) in losses_dict.items():\n",
    "        plt.plot(x, losses[from_epoch:num_epochs], label=label)\n",
    "    plt.legend(prop={'size': fsize})\n",
    "    plt.xlabel('Epoch', fontsize=fsize)\n",
    "    plt.xticks(x)\n",
    "    plt.grid()\n",
    "    plt.ylabel('MSE', fontsize=fsize)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=fsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-forward сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "QNetworkAmatrix = partial(QNetwork, additional_inputs=[{'tag': 'amatrix'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix = QNetworkAmatrix(10, activation='tanh', layers=[64, 64])\n",
    "ff_network_amatrix_64_3 = QNetworkAmatrix(10, layers=[64, 64, 64], activation='tanh')\n",
    "ff_network_amatrix_128_2 = QNetworkAmatrix(10, layers=[128, 128], activation='tanh')\n",
    "ff_network_amatrix_32_2 = QNetworkAmatrix(10, layers=[32, 32], activation='tanh')\n",
    "ff_network_amatrix_32_3 = QNetworkAmatrix(10, layers=[32, 32, 32], activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_losses = qnetwork_pretrain(ff_network_amatrix, shuffle(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_64_3_losses = qnetwork_pretrain(ff_network_amatrix_64_3, shuffle(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_128_2_losses = qnetwork_pretrain(ff_network_amatrix_128_2, shuffle(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_32_2_losses = qnetwork_pretrain(ff_network_amatrix_32_2, shuffle(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_32_3_losses = qnetwork_pretrain(ff_network_amatrix_32_3, shuffle(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_layers = np.array([ff_network_amatrix_losses,\n",
    "                          ff_network_amatrix_32_2_losses,\n",
    "                          ff_network_amatrix_32_3_losses,\n",
    "                          ff_network_amatrix_64_3_losses,\n",
    "                          ff_network_amatrix_128_2_losses]).transpose()\n",
    "\n",
    "losses_layers_df = pd.DataFrame(data=losses_layers, columns=['64x2', '32x2', '32x3', '64x3', '128x2'])\n",
    "losses_layers_df.to_csv('../logs/pre_train_data/layers_comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_layers_df = pd.read_csv('../logs/pre_train_data/layers_comparison.csv')\n",
    "\n",
    "ff_network_amatrix_losses = losses_layers_df['64x2']\n",
    "ff_network_amatrix_32_2_losses = losses_layers_df['32x2']\n",
    "ff_network_amatrix_32_3_losses = losses_layers_df['32x3']\n",
    "ff_network_amatrix_64_3_losses = losses_layers_df['64x3']\n",
    "ff_network_amatrix_128_2_losses = losses_layers_df['128x2']\n",
    "\n",
    "x = range(2, 11)\n",
    "fsize = 16\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(x, ff_network_amatrix_losses[1:], label='64x2 layers')\n",
    "plt.plot(x, ff_network_amatrix_32_2_losses[1:], label='32x2 layers')\n",
    "plt.plot(x, ff_network_amatrix_32_3_losses[1:], label='32x3 layers')\n",
    "plt.plot(x, ff_network_amatrix_128_2_losses[1:], label='128x2')\n",
    "plt.plot(x, ff_network_amatrix_64_3_losses[1:], label='64x3')\n",
    "plt.legend(prop={'size': fsize})\n",
    "plt.xlabel('Epoch', fontsize=fsize)\n",
    "plt.xticks(x)\n",
    "plt.grid()\n",
    "plt.ylabel('MSE', fontsize=fsize)\n",
    "plt.title('Comparison of FF network configurations by pre-training speed', fontsize=fsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_simple = QNetwork(10, activation='relu', layers=[64, 64])\n",
    "ff_network_amatrix = QNetworkAmatrix(10, activation='relu', layers=[64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_network = data[data['pkg_id'] < 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_simple_losses = qnetwork_pretrain(ff_network_simple, shuffle(data_full_network), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_losses = qnetwork_pretrain(ff_network_amatrix, shuffle(data), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_adam_losses = qnetwork_pretrain(ff_network_amatrix, shuffle(data),\n",
    "                                                   optimizer='adam', epochs=20, save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_adagrad_losses = qnetwork_pretrain(ff_network_amatrix, shuffle(data),\n",
    "                                                      optimizer='adagrad', epochs=20, save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_adadelta_losses = qnetwork_pretrain(ff_network_amatrix, shuffle(data),\n",
    "                                                       optimizer='adadelta', epochs=20, save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array([ff_network_amatrix_losses, ff_network_amatrix_adam_losses,\n",
    "                     ff_network_amatrix_adagrad_losses, ff_network_amatrix_adadelta_losses]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_df = pd.DataFrame(data=losses, columns=['rmsprop', 'adam', 'adagrad', 'adadelta'])\n",
    "losses_df.to_csv('../logs/pre_train_data/optimizer_comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_df = pd.read_csv('../logs/pre_train_data/optimizer_comparison.csv')\n",
    "\n",
    "ff_network_amatrix_losses = losses_df['rmsprop'][:10]\n",
    "ff_network_amatrix_adam_losses = losses_df['adam'][:10]\n",
    "ff_network_amatrix_adagrad_losses = losses_df['adagrad'][:10]\n",
    "ff_network_amatrix_adadelta_losses = losses_df['adadelta'][:10]\n",
    "\n",
    "x = range(1, 11)\n",
    "fsize = 25\n",
    "plt.figure(figsize=(13, 14))\n",
    "plt.plot(x, ff_network_amatrix_losses, label='RMSProp')\n",
    "plt.plot(x, ff_network_amatrix_adam_losses, label='Adam')\n",
    "plt.plot(x, ff_network_amatrix_adagrad_losses, label='AdaGrad')\n",
    "plt.plot(x, ff_network_amatrix_adadelta_losses, label='AdaDelta')\n",
    "plt.legend(prop={'size': fsize})\n",
    "plt.xlabel('Номер эпохи', fontsize=fsize)\n",
    "plt.xticks(x)\n",
    "plt.grid()\n",
    "plt.ylabel('MSE', fontsize=fsize)\n",
    "plt.title('Сравнение качества предобучения с разными\\n алгоритмами оптимизации (ReLU слои)', fontsize=fsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_tanh_amatrix = QNetworkAmatrix(10, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_tanh_amatrix_losses = qnetwork_pretrain(ff_network_tanh_amatrix, shuffle(data), epochs=10, save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_tanh_amatrix_adam_losses = qnetwork_pretrain(ff_network_tanh_amatrix, shuffle(data), epochs=10,\n",
    "                                                        optimizer='adam', save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_tanh_amatrix_adagrad_losses = qnetwork_pretrain(ff_network_tanh_amatrix, shuffle(data), epochs=10,\n",
    "                                                           optimizer='adagrad', save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_tanh_amatrix_adadelta_losses = qnetwork_pretrain(ff_network_tanh_amatrix, shuffle(data), epochs=10,\n",
    "                                                            optimizer='adadelta', save_net=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_tanh = np.array([ff_network_tanh_amatrix_losses, ff_network_tanh_amatrix_adam_losses,\n",
    "                        ff_network_tanh_amatrix_adagrad_losses, ff_network_tanh_amatrix_adadelta_losses]).transpose()\n",
    "losses_tanh_df = pd.DataFrame(data=losses_tanh, columns=['rmsprop', 'adam', 'adagrad', 'adadelta'])\n",
    "losses_tanh_df.to_csv('../logs/pre_train_data/optimizer_comparison_tanh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_c = cycler('color', ['k'])\n",
    "style_c = cycler('linestyle', ['-', '--', ':', '-.'])\n",
    "markr_c = cycler('marker', ['', '.', 'o'])\n",
    "c_cms = color_c * markr_c * style_c\n",
    "\n",
    "losses_tanh_df = pd.read_csv('../logs/pre_train_data/optimizer_comparison_tanh.csv')\n",
    "\n",
    "ff_network_tanh_amatrix_losses = losses_tanh_df['rmsprop']\n",
    "ff_network_tanh_amatrix_adam_losses = losses_tanh_df['adam']\n",
    "ff_network_tanh_amatrix_adagrad_losses = losses_tanh_df['adagrad']\n",
    "ff_network_tanh_amatrix_adadelta_losses = losses_tanh_df['adadelta']\n",
    "\n",
    "x = range(1, 11)\n",
    "fsize = 14\n",
    "ticksize = 10\n",
    "lw=3\n",
    "f = plt.figure(figsize=(7, 5))\n",
    "plt.plot(x, ff_network_tanh_amatrix_losses, label='RMSProp', linewidth=lw, alpha=0.6)#, color='k', linestyle='-')\n",
    "plt.plot(x, ff_network_tanh_amatrix_adam_losses, label='Adam', linewidth=lw, alpha=0.6)#, color='k', linestyle='--')\n",
    "plt.plot(x, ff_network_tanh_amatrix_adagrad_losses, label='AdaGrad', linewidth=lw)#, color='k', linestyle=':')\n",
    "plt.plot(x, ff_network_tanh_amatrix_adadelta_losses, label='AdaDelta', linewidth=lw)#, color='k', linestyle='-.')\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.xlabel('Epoch', fontsize=fsize)\n",
    "plt.xticks(x)\n",
    "plt.rc('xtick', labelsize=ticksize)\n",
    "plt.rc('ytick', labelsize=ticksize)\n",
    "plt.grid()\n",
    "plt.ylabel('MSE', fontsize=fsize)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Comparison of optimization algorithms by pre-training speed', fontsize=fsize)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"../img/opt-algos-pre-training-comparison.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout & stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_dropout_mid = QNetworkAmatrix(10, activation='relu', layers=[64, 'dropout', 64])\n",
    "ff_network_amatrix_dropout_end = QNetworkAmatrix(10, activation='relu', layers=[64, 64, 'dropout'])\n",
    "ff_network_amatrix_dropout_both = QNetworkAmatrix(10, activation='relu', layers=[64, 'dropout', 64, 'dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_dropout_mid_losses = qnetwork_pretrain(ff_network_amatrix_dropout_mid, shuffle(data), epochs=10,\n",
    "                                                          optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_dropout_end_losses = qnetwork_pretrain(ff_network_amatrix_dropout_end, shuffle(data), epochs=10,\n",
    "                                                          optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_network_amatrix_dropout_both_losses = qnetwork_pretrain(ff_network_amatrix_dropout_both, shuffle(data), epochs=10,\n",
    "                                                           optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = CachedEmbedding(LaplacianEigenmap, dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_network_no_inp = QNetwork(10, activation='relu', layers=[64, 64], embedding_dim=embedding.dim)\n",
    "embed_network_amatrix = QNetworkAmatrix(10, activation='relu', layers=[64, 64], embedding_dim=embedding.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_network_no_inp_losses = qnetwork_pretrain(embed_network_no_inp, shuffle(data), epochs=10,\n",
    "                                                embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_network_amatrix_losses = qnetwork_pretrain(embed_network_amatrix, shuffle(data_full_network), epochs=10,\n",
    "                                                 embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_network_no_inp_tanh = QNetwork(10, activation='tanh', layers=[64, 64], embedding_dim=embedding.dim)\n",
    "embed_network_amatrix_tanh = QNetworkAmatrix(10, activation='tanh', layers=[64, 64], embedding_dim=embedding.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_network_no_inp_tanh_losses = qnetwork_pretrain(embed_network_no_inp_tanh, shuffle(data_full_network), epochs=20,\n",
    "                                                     embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_network_amatrix_tanh_losses = qnetwork_pretrain(embed_network_amatrix_tanh, shuffle(data_full_network), epochs=20,\n",
    "                                                      embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses({\n",
    "    'no_inp_relu': embed_network_no_inp_losses,\n",
    "    #'amatrix_relu': embed_network_amatrix_losses,\n",
    "    #'no_inp_tanh': embed_network_no_inp_tanh_losses,\n",
    "    #'amatrix_tanh': embed_network_amatrix_tanh_losses\n",
    "})\n",
    "embed_network_no_inp_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конвейеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_emb = CachedEmbedding(LaplacianEigenmap, dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_network_ng_emb = QNetwork(22, scope='conveyor_test_ng', activation='relu', layers=[64, 64],\n",
    "                                   embedding_dim=conv_emb.dim)\n",
    "conveyor_network_ng_amatrix = QNetwork(22, scope='conveyor_test_ng', activation='tanh', layers=[64, 64],\n",
    "                                       additional_inputs=[{'tag': 'amatrix'}])\n",
    "conveyor_network_ng_full = QNetwork(22, scope='conveyor_test_ng', activation='tanh', layers=[64, 64],\n",
    "                                    additional_inputs=[{'tag': 'amatrix'}, {'tag':'work_status'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conv_ng = pd.read_csv('../logs/data_conveyor_gen_energy_test_oneinp.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conv_ng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_network_ng_emb_losses = qnetwork_pretrain(conveyor_network_ng_emb, shuffle(data_conv_ng), epochs=20,\n",
    "                                                   embedding=conv_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_network_ng_amatrix_losses = qnetwork_pretrain(conveyor_network_ng_amatrix, shuffle(data_conv_ng), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conveyor_network_ng_full_losses = qnetwork_pretrain(conveyor_network_ng_full, shuffle(data_conv_ng), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses({\n",
    "    'no_inp': conveyor_network_ng_emb_losses,\n",
    "    #'amatrix': conveyor_network_ng_amatrix_losses,\n",
    "    #'amatrix_work_status': conveyor_network_ng_full_losses,\n",
    "})\n",
    "conveyor_network_ng_emb_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
